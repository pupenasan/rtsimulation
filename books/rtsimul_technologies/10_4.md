[10.3 <--- ](10_3.md) [   Зміст   ](README.md) [--> 10.5](10_5.md)

## 10.4. EXPERIMENTAL RESULTS

The methodology has been tested on a large set of OpenMP-based benchmarks (namely the OMPScr suite) and a large parallel application, namely ffmpeg (video encoding/decoding).

Методологію перевірено на великому наборі тестів на основі OpenMP (а саме пакеті OMPScr) і великій паралельній програмі, а саме ffmpeg (кодування/декодування відео).

The basic assumption of this work is that the system is subject to a mixed application workload: a computationally intensive element with soft real-time constraints and a set of elements with very strict hard real-time characteristics, here called computational and real-time parts, respectively. The number and parameters of both the computational and real-time parts varies and strictly depends on the system being considered. This model well represents applications such as observation spacecraft payload, where massive data processing is required with high availability, while response to external stimuli within a given time is paramount (e.g., for the spacecraft’s navigation system).

Основне припущення цієї роботи полягає в тому, що система піддається змішаному робочому навантаженню: обчислювально інтенсивний елемент із м’якими обмеженнями реального часу та набір елементів із дуже строгими характеристиками жорсткого реального часу, які тут називаються обчислювальними частинами та частинами реального часу. , відповідно. Кількість і параметри як обчислювальної частини, так і частини реального часу змінюються і суворо залежать від системи, що розглядається. Ця модель добре представляє такі додатки, як корисне навантаження космічного корабля спостереження, де необхідна масивна обробка даних із високою доступністю, тоді як реакція на зовнішні подразники протягом певного часу є першорядною (наприклад, для навігаційної системи космічного корабля).

The purpose of our methodology is to answer a set of key questions during the development of real-time applications running on an MPSoC:

1. What is the performance of the real-time applications? Is the system missing any deadlines with the current hardware and scheduling setup?

2. What is the performance of the computational part? Is it performing within requirements?

3. How much performance can the current hardware and software setup deliver? Is it possible to add additional computational or real-time tasks without affecting global performance? Can we reduce the number of hardware resources? What is the benefit of moving parts of the application or OS to hardware?

Метою нашої методології є відповідь на набір ключових запитань під час розробки додатків реального часу, що працюють на MPSoC:

1. Яка продуктивність програм реального часу? Чи не втрачаються системою будь-які терміни з поточним обладнанням і налаштуваннями планування?

2. Яка продуктивність обчислювальної частини? Чи відповідає він вимогам?

3. Яку продуктивність може забезпечити поточне налаштування апаратного та програмного забезпечення? Чи можна додати додаткові обчислювальні завдання або завдання в реальному часі, не впливаючи на загальну продуктивність? Чи можемо ми зменшити кількість апаратних ресурсів? Яка користь від перенесення частин програми чи ОС на обладнання?

All tests have been executed using ReSP on a multi-ARM architecture consisting of a variable number of cores with caches, and a shared memory, all interconnected by a shared bus. Simulations where timing was recorded were run on a Core 2 Duo 2.66GHz Linux machine.

Усі тести були виконані з використанням ReSP на архітектурі з декількома ARM, що складається зі змінної кількості ядер із кеш-пам’яттю та спільної пам’яті, які з’єднані спільною шиною. Симуляції, у яких фіксувався час, проводилися на системі Linux Core 2 Duo 2,66 ГГц.

To evaluate the performance and accuracy of OS emulation with respect to a real OS, twelve OmpSCR benchmarks were run with the real-time operating system eCos [15], using a 4-core platform. A large set of eCos system calls were measured running six of these benchmarks as a training or calibration set, and the average latency of each class of system calls was determined. The Lilliefors/Van Soest test of normality [16] applied to the residuals of each class shows evidence of nonnormality (*L* = 0.30 and *L*critical = 0.28 with α = .01), but given that the population variability remains limited (with a within-group mean square MSS(A) = 7602 clock cycles), it can be assumed that each average latency is representative of its class.

Щоб оцінити продуктивність і точність емуляції ОС відносно реальної ОС, було запущено дванадцять тестів OmpSCR з операційною системою реального часу eCos [15], використовуючи 4-ядерну платформу. Було виміряно великий набір системних викликів eCos, запустивши шість із цих контрольних тестів як набір для навчання або калібрування, і було визначено середню затримку кожного класу системних викликів. Тест нормальності Лілліфорса/Ван Соста [16], застосований до залишків кожного класу, показує докази ненормальності (*L* = 0,30 і *L*критичне = 0,28 з α = 0,01), але враховуючи, що мінливість популяції залишається обмеженою (із середнім квадратичним значенням MSS(A) усередині групи = 7602 тактових циклів), можна припустити, що кожна середня затримка відповідає своєму класу.

The derived latencies were introduced for each system call in our OS emulation system, and the remaining six benchmarks (used as a validation set) were executed. Since profiling did not include all functions used by the OS and for which the latency was considered zero, the overall results were uniformly biased for underestimation. This bias can be easily corrected considering the average error, leading to an average error of 6.6 ± 5.5%, as shown in Figure 10.5. Even with this simple scheme, the methodology can very well emulate the behavior of a specific OS with minimal error, especially considering that full code equivalence is present for the application and library functions, but threading, multiprocessor management, and low-level OS functions are emulated.

Отримані затримки були введені для кожного системного виклику в нашій системі емуляції ОС, а решта шість тестів (використаних як набір перевірки) були виконані. Оскільки профілювання не включало всі функції, що використовуються ОС і для яких затримка вважалася нульовою, загальні результати були рівномірно зміщеними для недооцінки. Це зміщення можна легко виправити, враховуючи середню помилку, що призводить до середньої помилки 6,6 ± 5,5%, як показано на малюнку 10.5. Навіть з цією простою схемою методологія може дуже добре імітувати поведінку конкретної ОС з мінімальними помилками, особливо враховуючи, що повна еквівалентність коду присутня для функцій програми та бібліотеки, але потоки, багатопроцесорне керування та функції ОС низького рівня є емульований.

In addition, the use of the OS emulation layer introduces a noticeable speedup (13.12 ± 6.7 times) when compared to running the OS on each ISS. This is because of several factors, including the absence of some hardware components such as debugging UARTs and timers (the TE implements a terminal in the host OS and the configuration manager uses SystemC and its events to keep track of time), and the fact that, in our mechanism, idle processors do not execute busy loops but they are, instead, suspended. The latter is implemented by trapping the busy loop wait function in the TE and redirecting it to a SystemC wait() call.

Крім того, використання рівня емуляції ОС забезпечує помітне прискорення (13,12 ± 6,7 разів) порівняно з запуском ОС на кожній ISS. Це пов’язано з декількома факторами, включаючи відсутність деяких апаратних компонентів, таких як UART для налагодження та таймери (TE реалізує термінал у головній ОС, а менеджер конфігурації використовує SystemC та його події для відстеження часу), а також той факт, що , у нашому механізмі неактивні процесори не виконують цикли зайнятості, а натомість призупиняються. Останнє реалізовано шляхом перехоплення функції очікування циклу зайнятості в TE та перенаправлення її на виклик SystemC wait().

Using the proposed methodology, a designer can verify the real-time performance of a multiprocessor system under load and explore the use of different interrupt distribution and handling schemes. As proof-of-concept, we ran the benchmarks as computationally intensive applications, while the real-time tasks are implemented by synthetic functions, with varying deadlines. These functions can be categorized as (1) housekeeping (scheduled regularly, perform sanity checks, repetitive tasks, etc.) and (2) response to external events (when an alarm is fired, its response is usually required within a given deadline).

Використовуючи запропоновану методологію, розробник може перевірити в режимі реального часу продуктивність багатопроцесорної системи під навантаженням і вивчити використання різних схем розподілу та обробки переривань. Для підтвердження концепції ми провели тести як додатки з інтенсивним обчисленням, тоді як завдання в реальному часі реалізуються синтетичними функціями з різними термінами виконання. Ці функції можна класифікувати як (1) домашнє обслуговування (регулярне проведення, перевірка працездатності, повторювані завдання тощо) і (2) реагування на зовнішні події (коли спрацьовує сигнал тривоги, його реагування зазвичай вимагається протягом заданого терміну).

![image-20220822182349486](media/image-20220822182349486.png)

**FIGURE 10.5** Simulation speedup and estimation error using the emulation layer instead of eCos.

A first analysis that is performed with the current methodology is to run the realtime part separately from the computational part, reducing all OS-related latencies (such as the latency of the mutex lock operation) to zero. The obtained *concurrency* *profile* shows the number of active PEs in time, that is, the effective utilization of the system resources. A similar graph is derived for the computational part, allowing the designer to determine if sufficient resources are available to run the application within its performance constraints. Finally, the computational and real-time parts are combined together and the concurrency profile is drawn as shown in Figure 10.6. This graph helps the designer tweak the hardware and software to match the desired requirements. As an example, the combination diagram (Figure 10.6b) can show a lower-than-expected utilization in case access to a shared bus represents a bottleneck in the system. If, instead, utilization is already at a maximum, the designer can conclude that more processing elements are necessary to reach the performance requirements. Simulating the system with realistic OS-related latencies (that can be targeted to any possible OS choice) leads to determining the best OS choice for the current application.

Перший аналіз, який виконується за поточною методологією, полягає в тому, щоб запустити частину реального часу окремо від обчислювальної частини, зменшуючи всі затримки, пов’язані з ОС (наприклад, затримку операції блокування м’ютексу), до нуля. Отриманий *профіль* *паралелізму* показує кількість активних PE в часі, тобто ефективне використання ресурсів системи. Подібний графік виводиться для обчислювальної частини, що дозволяє розробнику визначити, чи достатньо ресурсів для запуску програми в межах її обмежень продуктивності. Нарешті, обчислювальна частина та частина реального часу об’єднуються разом і малюється профіль паралельності, як показано на малюнку 10.6. Цей графік допомагає дизайнеру налаштувати апаратне та програмне забезпечення відповідно до бажаних вимог. Як приклад, комбінована діаграма (рис. 10.6b) може показати нижче, ніж очікувалося, використання у випадку, якщо доступ до спільної шини є вузьким місцем у системі. Якщо, натомість, використання вже є максимальним, розробник може зробити висновок, що для досягнення вимог до продуктивності необхідно більше елементів обробки. Моделювання системи з реалістичними затримками, пов’язаними з ОС (які можна націлити на будь-який можливий вибір ОС), призводить до визначення найкращого вибору ОС для поточної програми.

![image-20220822182424213](media/image-20220822182424213.png)

**FIGURE 10.6** The concurrency profiles of the ffmpeg benchmark, showing the computational parts (a) and the combination of the computational and real-time parts (b).

**МАЛЮНОК 10.6** Профілі паралелізму тесту ffmpeg, що показує обчислювальні частини (a) і поєднання обчислювальних частин і частин реального часу (b).

Figure 10.7 shows how the methodology is used to determine the best scheduler for the system where the performance is graphed for two schedulers (Priority and EDF). Running the application with and without RT tasks shows the different computational performance of the system, as depicted in Figure 10.8. As in our methodology, the RT or non-RT status of a task can be changed without modifications to the code, and this evaluation is simply made with two runs of the simulator. The designer can see how changes in the OS scheduling affect the performance of the system.

На рисунку 10.7 показано, як методологія використовується для визначення найкращого планувальника для системи, де продуктивність представлена на графіку для двох планувальників (пріоритетного та EDF). Запуск програми з завданнями RT і без них показує різну обчислювальну продуктивність системи, як показано на малюнку 10.8. Як і в нашій методології, статус RT або не RT завдання можна змінити без змін коду, і ця оцінка просто виконується за допомогою двох прогонів симулятора. Розробник може побачити, як зміни в плануванні ОС впливають на продуктивність системи.

![image-20220822182445294](media/image-20220822182445294.png)

**FIGURE 10.7** Fraction of missed deadlines with different schedulers and high real-time workload (1 kHz).

![image-20220822182500539](media/image-20220822182500539.png)

**FIGURE 10.8** The performance impact of the real-time (RT) part on the computational part, that is, their relative execution time when compared to execution without the RT part. 

[10.3 <--- ](10_3.md) [   Зміст   ](README.md) [--> 10.5](10_5.md)