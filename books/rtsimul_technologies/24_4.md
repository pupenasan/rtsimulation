[24.3 <--- ](24_3.md) [   Зміст   ](README.md) [--> 24.5](24_5.md)

## 24.4 SIMULATION WITH A SINGULAR MASS MATRIX

In Section 24.3, the mass matrix of the unconstrained dynamic equations must have full rank if the mass matrix of the reduced order equations (**M** ) is to be inverted during simulation. If some of the very small masses of fluid are made equal to zero to remove the high-frequency dynamics that they introduce, then this assumption will no longer hold. If **M** is singular, then the dynamic equations in Equation 24.13 are said to be quasi-linear DAEs, and an extensive description of the techniques available to solve this type of system is given in Ref. [11]. Sections 24.4.1 to 24.4.5 describe the method of determining the index of the resulting DAEs when the mass matrix is singular and also a method of simulating the equations.

### 24.4.1 Index of Differential Algebraic Equations

The index of the DAEs is found by extracting the “hidden” algebraic constraints from the original equations. The algebraic constraints **G0** are determined by projecting the dynamic equations in Equation 24.13 onto the null space of the mass matrix using the projection **β** that satisfies Equation 24.19. The resulting constraint equations in Equation 24.20 define the manifold on which the states can travel.

The dynamics of the constrained system is then found by augmenting the original equations with motion at a local tangent to the constraint manifold, as shown in Equation 24.21. If the augmented mass matrix has full column rank, then the system has index 1. If the mass matrix does not have full column rank, then the above procedure is repeated. That is, the hidden constraints of the augmented system are determined and a new system of equations is derived by augmenting the dynamic equations with the derivative of the new constraints. The index of the DAEs is defined by the number of times the procedure must be repeated before the augmented mass matrix has full column rank.

 ![image-20220823012315933](media/image-20220823012315933.png)

![image-20220823012354709](media/image-20220823012354709.png)

The hydraulics models in Equation 24.13 have index 1, and it is feasible to simulate the system of overdetermined equations in Equation 24.21 directly. The problem is that the number of independent states is defined by the size of the state vector minus the number of hidden algebraic constraints. The initial values of the full state vector must therefore be consistent (i.e., lie on the constraint manifold), and any drift from the constraint manifold during the simulation must be controlled. The approach discussed in Ref. [11] overcomes these issues by selecting a minimum number of independent integrated states from the state vector. The integrated states can then be used to determine algebraically the remaining states so that the hidden constraints are satisfied. This is similar to the method described in Section 24.3, but now, the constraints are defined by nonlinear functions of the states, and they are implicit within the model description. 

### 24.4.2 Minimum Order Dynamic Equations

A minimal order system of dynamic equations can be derived by partitioning the state vector **v** in Equation 24.22 into independent states v i that are integrated in time and algebraic states **v** a that are derived at each time step from a function of the integrated states. The reordering of the integrated and algebraic states into the full state vector is achieved through the permutation matrix **Π**. The selection of which independent states are chosen from the full state vector is the same as in Section 24.3, namely by inspection of the symbolically derived null-space matrix **β**.

![image-20220823012434916](media/image-20220823012434916.png)

The rate of change of the algebraic states is derived by differentiating the constraint equations in Equation 24.20 to give Equation 24.23, where the time dependency of the orifice areas in the constraint equations is accounted for by the third term in *t* .

 ![image-20220823012450923](media/image-20220823012450923.png)

Rearranging Equation 24.23 into Equation 24.24, and substituting into the original equations in Equation 24.13, produces the minimum order dynamic equations in Equation 24.25, where the columns of **P** form the the basis vectors of the range space of the mass matrix. These equations represent a minimal order system of ODEs that satisfy **G0** and where the resulting mass matrix is invertible. The problem is now to determine the relationship between the integrated and algebraic states when the constraint equations are nonlinear in nature.

![image-20220823012512586](media/image-20220823012512586.png)

This section describes the derivation of the relationship between the integrated and the algebraic states in the reduced order model. On the basis of the original formulation of the forcing function in Equation 24.5, the algebraic constraints can be expressed in Equation 24.26 in terms of the partitioning of the state vector in Equation 24.7. The matrix representing the pressure drop across open orifices (**WO**) is partitioned in Equation 24.27, and the dependent states (**v**ˆ) are related to the independent states (**v** ) by Equation 24.28. The notation **v** |**v**| in Equation 24.26 defines the signed square value of each element in the state vector.

 ![image-20220823012532129](media/image-20220823012532129.png)

The constraints in Equation 24.26 can be rearranged in Equation 24.29 for the unknowns **v** a, where the matrices **A**, **B**, **C**, **D** are given by Equations 24.30 through 24.33.

![image-20220823012554243](media/image-20220823012554243.png)



### 24.4.4 Solving Systems of Polynomial Equations

There are a number of ways to solve the system of polynomial equations in Equation 24.29 for the unknown states. The approach chosen is the iterative Newton (or Newton–Raphson) method given in Equation 24.34, where the Jacobian of the constraint matrix is given by Equation 24.35. This approach has proven to be robust, and standard ODE solvers can still be utilized as the iterative procedure is only invoked when the solver requires the derivatives of the independent integrated states. The iterative procedure is still considered an acceptable approach if the equations are to be implemented in a real-time simulation code, as the maximum number of iterations can be limited to guarantee that the solution will be found in the available time.

![image-20220823012632258](media/image-20220823012632258.png)

Rather than inverting the Jacobian matrix, the velocity states are updated at each iteration by solving the system of linear equations in Equation 24.36 for the increment in the velocity estimates ∆**v**.

![image-20220823012649308](media/image-20220823012649308.png)

The equations in Equation 24.36 are solved using the **QR** decomposition of the Jacobian matrix in Equation 24.37, where **Q** is orthogonal, **R** is upper triangular, and **E** is a permutation matrix determined so that the values on the leading diagonal of **R** are in decreasing order. The **QR** decomposition is determined during the simulation using the FORTRAN **DGEQP3** function provided in the work by Anderson et al. [12] and described in the work by Quintana-Ort et al. [13]. The efficiency of these routines compared to other implementations is outlined in the work by Foster and Liu [14].

![image-20220823012708013](media/image-20220823012708013.png)

Substituting the matrix **QR** decomposition into Equation 24.36 and multiplying through by **Q****T** leads to Equation 24.38. This equation can easily be solved for ∆**z** as **R** is upper triangular. The calculated solution is reordered into the desired vector of increments using the permutation matrix in Equation 24.39.

![image-20220823012722400](media/image-20220823012722400.png)

An additional benefit of decomposing the Jacobian in this way is that it provides an estimate for the rank of the matrix. The diagonal elements of **R** provide an approximation to the singular values, and any singular value near zero indicates that the matrix is rank deficient. If that is the case, then a minimum norm solution can be derived using the more accurate SVD described in Section 24.4.5.

### 24.4.5 Local Singularities in Algebraic Equations

Under certain conditions, the Jacobian of the constraint equations may be locally singular. This can occur when the orifice areas become very small just before, or after, a transition between modes. In this case, a modified Newton’s method is used (see Ref. [15]), where the aim is to determine the minimum norm solution to the equations, that is, the solution where the state vector has the smallest magnitude. The method uses a generalized outer inverse of the Jacobian to update the state vector. The outer inverse is determined using the more robust SVD of the Jacobian. The form of the decomposition is given in Equation 24.40, where **U** and **V** are orthogonal matrices, **Σ** is a diagonal matrix containing the singular values, and the rank of the Jacobian (*r*) is given by the number of nonzero diagonal elements in Σ.

![image-20220823012758156](media/image-20220823012758156.png)

An outer inverse (denoted by #) of the Jacobian is defined as any matrix where the relationship in Equation 24.43 is satisfied. On the basis of the SVD, an outer inverse can be shown to be given by Equation 24.44, and the modified Newton method is then given by Equation 24.45. The SVD is calculated during the simulation using the FORTRAN **DGESVD** function in Ref. [12], and although it is computationally more expensive to calculate compared to the **QR** decomposition described previously, the fact that it is only required at a few points during the simulation means that it does not adversely affect the efficiency of the simulation approach.

![image-20220823012815485](media/image-20220823012815485.png)

![image-20220823012828531](media/image-20220823012828531.png)

[24.3 <--- ](24_3.md) [   Зміст   ](README.md) [--> 24.5](24_5.md)