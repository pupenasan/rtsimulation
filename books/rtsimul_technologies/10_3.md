[10.2 <--- ](10_2.md) [   Зміст   ](README.md) [--> 10.4](10_4.md)

## 10.3. PROPOSED METHODOLOGY

For the implementation and evaluation of the design methodology presented in this study, we use the open source simulation platform ReSP [11]. ReSP is based on the SystemC library and it targets the modeling of multiprocessor systems. Its most peculiar feature consists in the integration of C++ and Python programming languages; this augments the platform with the concept of reflection [12], allowing full observability and control of every C++ or SystemC element (variable, method, etc.) specified in any component model. In this work, we exploit and extend ReSP’s system call emulation subsystem to support the analysis of real-time systems and applications. The presented functionalities are used for preliminary exploration of the applications’ behavior for guiding the designer in the choice of the target RTOS and as a support for early HW/SW codesign.

### 10.3.1 System Call Emulation

*System call emulation* is a technique enabling the execution of application programs on an ISS without the necessity to simulate a complete OS. The low-level calls made by the application to the OS routines (*system calls*, SC) are identified and intercepted by the ISS and then redirected to the host environment, which takes care of their actual execution. Suppose, for example, that the simulated application program contains a call to the open routine to open file *“filename*.*”* Such a call is identified by the ISS and routed to the host OS, which actually opens *“filename”* on the filesystem of the host. The file handle is then passed back to the simulated environment. A simulation framework with system call emulation capabilities allows the application developers to start working as early as possible, even before a definitive choice about the target OS is performed. This can also help in the selection, customization, configuration, and validation of the OS itself. Figure 10.1 shows an overview of ReSP’s system call emulation mechanism. Here, each ISS communicates with one centralized trap emulator (TE), the component responsible for forwarding SCs from the simulated environment to the host. To ensure independence between the ISS and the TE, interfaces (IF-1,IF-2, etc.) are created and communication between the TE and the ISS exclusively takes place through them.

![image-20220822181858441](E:\san\Технології\моделиров\gitver_rtsimul\books\rtsimul_technologies\media\image-20220822181858441.png)

**FIGURE 10.1** Organization of the simulated environment including system call emulation.

Figure 10.2 shows the system call emulation mechanism where each ISS communicates with the centralized TE, the component responsible for forwarding the system calls from the simulated to the host environment.

Instead of identifying the SCs through particular assembly instructions or special addresses (as in most simulator environments), we use the name (i.e., the symbol) of the corresponding routine. When the application program is loaded, the names of the low-level SCs (e.g., sbrk, _open, etc.) are associated with their addresses in the binary file and registered with the TE. At runtime, the ISS then checks for those addresses, and when one is found, the corresponding SC is emulated on the host environment.

The TE provides the emulation of concurrency management routines with an additional unit, called a *concurrency manager* (CM), where the TE intercepts calls for thread creation, destruction, synchronization etc. For this purpose, we created a placeholder library containing all the symbols (i.e., the function identifiers) of the POSIX-Thread standard, but without a corresponding implementation. This ensures that programs using the pthread library can correctly compile. During execution, all calls to pthread routines are trapped and forwarded to the CM. If the application software is compiled with a recent GNU GCC compiler (at least version 4.2), it is also possible to successfully emulate OpenMP directives. The CM is able to manage shared memory platforms with an arbitrary number of symmetric processors.

In addition to system call emulation, these functionalities can be used, through the CM, for the emulation of concurrency management (thread creation, destruction, mutex lock, unlock, etc.) routines. With respect to previous work, these mechanisms demonstrate the following advantages:

1. *Independence from the cross-compiler toolchain*: since the names of the system call routines are used, it is not necessary to adhere to the conventions with which the software is built or to create fictitious jumps in the code.

2. *High interoperability with different ISS types*: the IF is the only component that requires customization to allow a new ISS to be integrated with the TE.

3. *Extensibility*: the presented mechanism can also be used for preliminary HW/SW partitioning. Moreover, by emulating the POSIX-Threads routines, multithreaded applications can be easily simulated.

![image-20220822181947602](E:\san\Технології\моделиров\gitver_rtsimul\books\rtsimul_technologies\media\image-20220822181947602.png)

**FIGURE 10.2** Internal structure and working mechanisms of the function trap emulator.

Since only the low-level SCs (e.g., sbrk) are emulated and the rest of the OS code (e.g., malloc) is executed unmodified in the ISS, our method maintains high code equivalence with the final software, even at the assembly level.

Communication between the emulator and the ISS is a critical point in the overall design. On the one hand, it must be designed to be flexible and portable so that ISSs can be easily plugged into the system. On the other hand, it must be as fast as possible to guarantee high simulation speed. These are conflicting requirements and a proper trade-off must be determined. Two solutions were identified: the first is purely based on compiled C++, while the second, more flexible, one uses Python to unintrusively access the ISS internal variables.

To guarantee the timing accuracy of each input/output (I/O)-related SC (such as the write operation), which would generate traffic on the communication medium, we assume the SC is executed inside the processor, modeling only the data transfer from processor to memory and vice-versa. While this is only an approximation of an actual system, accuracy is not severely affected as shown by our experiments.

### 10.3.2 Pthreads as a Real-Time Concurrency Model

Pthreads are a well known concurrent application programming interface (API) and, as part of the POSIX standard, are available for most operating systems (either natively or as a compatibility layer). The Pthread API provides extensions for managing real-time threads, in the form of two scheduling classes:

**FIFO**: threads of equal priority are scheduled following a first-come first- served policy; if a thread of high priority is created while one of lower priority is running, the running thread is preempted.

**Round-robin**: same scheduling policy of *FIFO*, with the difference that the processor is shared, in a round robin fashion, among threads of equal priority.

To manage these functionalities, Pthreads provide routines for setting/reading/ changing thread priorities and scheduling policies. However, even when using the POSIX-Threads RT extension, the standard does not fully allow the management of RT systems. Important features, such as task scheduling based on deadlines, are not present and this prevents an effective modeling and analysis of a wide range of RT systems. For this reason, our emulation layers extend the POSIX-Thread standard with the introduction of the *earliest deadline first* (EDF) [13] scheduling policy and with the possibility of declaring a task as unpreemptible. Theoretical results [14] expose that EDF scheduling brings better performance with respect to standard priority-based scheduling. In our implementation, the emulated RT features are compatible with the popular OS RTEMS task management policies.

This work enables the exploration, tuning, and analysis of RT systems. To effectively and efficiently perform such activities, we must be able to explore the task scheduling policies, their priorities, and in general, task attributes. As modifying the source code is not suitable for fast coexploration, thread attributes and scheduling policies can be specified also *outside* the simulation space, using ReSP capabilities. Figure 10.3 shows how ReSP can be used to tune a given system using an optimization loop: attributes are set, the system is simulated, the simulation results can be used to change the system parameters, and so on. The designer has two possible alternatives: (1) specifying the desired RT behavior directly in the application source code or (2) via Python scripting. The first mechanism is simply obtained by emulation of all threading-related primitives. In particular, the calls made by the application software to the functions for managing thread attributes are redirected to the CM, which takes care of managing and scheduling the tasks according to such attributes. The second method consists of using Python to directly export the internal structure of the CM to ReSP. As such, it is possible, either before or during the simulation, to modify the CM status and change the thread management policies without modifications to the application source code. In both cases, the system load and RT behavior can be modified during simulation, enabling an effective exploration of the system’s real-time behavior.

![image-20220822182053963](E:\san\Технології\моделиров\gitver_rtsimul\books\rtsimul_technologies\media\image-20220822182053963.png)

**FIGURE 10.3** Exploration flow of real-time policies. Note how task attributes are modified at runtime through the Python console.

### 10.3.3 Real-Time Concurrency Manager

As mentioned in Section 10.3.1, the TE provides the emulation of concurrency management routines with an additional unit, the CM. The overall mechanism is analogous to the one depicted in [Figure 10.2](#_bookmark60), but instead of trapping I/O or memory management, the TE traps routines for thread creation, destruction, synchronization, etc. During execution, all calls to pthread routines are trapped and forwarded to the CM in the simulator environment. If the application software is compiled with a recent GNU GCC compiler (at least version 4.2), it is also possible to successfully emulate OpenMP directives.

This CM was augmented to deal with real-time extensions and to correctly keep statistics about issues such as missed deadlines, serviced interrupts, etc. In particular, the following features were added: 

•   **Context Switch Capabilities**. To execute different threads on the same processor, *context switch* capabilities are necessary because a processor can switch between two threads either when the current thread is blocked (e.g., for synchronization) or when the time quantum associated with the current thread expires. Switching context consists of saving all the ISS registers and restoring the registers for the next thread, much like what would happen when using a nonemulated OS, with the only difference that registers are not saved on the stack in memory, but in the simulator’s space.

•   **Real-Time Scheduler**. We implemented the real-time scheduler in three different versions: *FIFO, Round-Robin*, and *EDF.* Each task can be assigned a scheduling policy and tasks with different policies can coexist in the system. [Figure 10.4 ](#_bookmark61)shows how the scheduler is implemented inside the CM and communicates with the rest of the system through the TE. Each task, according to the selected policy, is inserted in a specific queue. Policies of tasks can be varied at runtime either from the application code or by directly interacting with ReSP through the Python console. The latter mechanism has been implemented to enable flexible task management, thus allowing an effective and efficient exploration of the different scheduling policies and priorities and the different RTOS configurations. Tasks with the EDF policy are assigned the highest priority. The scheduler is able to manage shared memory platforms with an arbitrary number of symmetric processors. Since scheduling and, in general, task management operations are performed in the host environment, it is possible to add features such as deadlock and race-condition detection without altering the system behavior. Because of this, our system can also be successfully employed for verification of system correctness. In contrast, if such features as deadlock and race-condition detection were implemented in the simulated software, system behavior would be affected and disallow the verification.

![image-20220822182143425](E:\san\Технології\моделиров\gitver_rtsimul\books\rtsimul_technologies\media\image-20220822182143425.png)

**FIGURE 10.4** Detailed structure of the real-time concurrency manager (CM). The CM communicates with the simulated application through the trap emulator. In the CM, RT tasks are organized in queues of different priorities.

•   **Interrupt Management**. The interrupt management is composed of an emulated interrupt generator and an interrupt service routine (ISR) manager. While the former is present only to emulate external events and to force execution of ISRs (to enable the analysis of the system behavior under different practical environmental conditions), the latter feature is used to deal with ISRs, no matter how they are triggered. No major modifications were necessary to the system to control ISRs since, after creation, they are treated as standard real-time tasks.

•   **Python Integration**. This feature enables task control from outside of the simulated application. This means that from ReSP’s interactive shell it is possible to manage task priorities, deadlines, etc. As such, it is not necessary to modify the simulated software to perform an effective exploration and to analyze the effects of different scheduling policies and/or priorities. 

### 10.3.4 Interrupt Management

Reactivity to external events is a fundamental feature in embedded systems, expecially for what concerns real-time applications; most of the time such systems have to react in a timely and predictable manner to inputs coming from the outside world.

The interrupt management system implemented in ReSP’s CM has two operating modes: interrrupts can either be triggered by simulated peripheral components described in SystemC (thus mimicking the actual system behavior) or they can be artificially raised by the CM, to ease the analysis of the systems’ real-time behavior under particular stress conditions. The latter mechanism is particularly useful to quickly emulate, explore, and analyze the behavior in different environmental conditions.

In both ways ISRs are managed by the CM and they are treated like normal tasks, meaning that any function can be defined as an ISR. As such, custom priorities, scheduling policies, etc. can be associated to these routines as explained above for standard tasks. Parameters such as generation frequency, temporal distribution, interrupt type, etc. can be easily set and changed even at runtime using ReSP reflective capabilities, thus allowing an effective exploration of the configuration alternatives and a simple emulation of the possible environmental conditions.

[10.2 <--- ](10_2.md) [   Зміст   ](README.md) [--> 10.4](10_4.md)