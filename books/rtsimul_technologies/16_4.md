[16.3 <--- ](16_3.md) [   Зміст   ](README.md) [--> 16.5](16_5.md)

## 16.4. CONCURRENT SIMULATION APPROACH FOR ARBITRARY EVENT PROCESSES

In this section, we describe a method for solving the constructability problem with- out having to rely on the Markovian structure of the event processes in the DES model, based on the sample path coupling approach first presented in the work by Cassandras and Panayiotou.4 We start by making some assumptions, followed by three subsections. Section 16.4.1 introduces some notation and definitions; Section

16.4.2 presents the *Time Warping Algorithm* (TWA) for implementing the general solution to the constructability problem; Section 16.4.3 quantifies the speedup real- ized through the TWA; and Section 16.4.4 discusses extensions resulting from relax- ing the assumptions presented next.

The four assumptions that follow simplify our analysis and apply to a large class of DES. However, they can also be eventually relaxed (see the work by Cassandras and Panayiotou4).

 

(**A1**) *Feasibility Assumption*: Let *xn* be the state of the DES after the occur- rence of the *n*th event. Then, for any *n*, there exists at least one *r* > *n* such that *e* ∈ *Γ*(*xr*) for any *e* ∈ *E*.

(**A2**) *Invariability Assumption*: Let *E* be the event set under the nominal parameter θ0 and let *E**m* be the event set under θ*m* ≠ θ0. Then, *E**m* = *E*.

(**A3**) *Similarity Assumption*: Let G*i*(θ0), i ∈ *E* be the event lifetime distribution

for the event *i* under θ0 and let G*i*(θ*m*), i ∈ *E* be the corresponding event lifetime distribution under θ*m*. Then, G*i*(θ0) = G*i*(θ*m*) for all i ∈ *E*.

(**A4**) *State Invariability Assumption*: Let G*i*(*xk*), *i* ∈ *E* and *xk* ∈ *X* be the event

lifetime distribution of event *i* if *i* is activated when the system state is *xk*. Then, G*i*(*xk*) = G*i*(*xl*) for all *xk*, *xl* ∈ *X* and all *i* ∈ *E*.

Assumption **A1** guarantees that in the evolution of any sample path, all events in

*E* will always become feasible at some point in the future. If, for some DES, assump- tion **A1** is not satisfied, that is, there exists an event α that never gets activated after some point in time, then, as we will see, it is possible that the construction of some sample path will remain suspended forever waiting for α to happen. Note that a DES with an irreducible state space immediately satisfies this condition.

Assumption **A2** states that changing a parameter from θ0 to some θ*m* ≠ θ0 does not alter the event set *E*. More importantly, **A2** guarantees that changing to θ*m* does not introduce any new events so that all event lifetimes for all events can be observed

from the nominal sample path (the converse, i.e., fewer events in *Em*, would still make it possible to satisfy (**OB**)).

Assumption **A3** guarantees that changing a parameter from θ0 to some θ*m* ≠ θ0

does not affect the distribution of one or more event lifetime sequences. This allows

us to use exactly the same lifetimes that we observe in the nominal sample path to construct the perturbed sample path. In other words, our analysis focuses on *structural* system parameters rather than *distributional* parameters. As we will see, however, it is straightforward to handle the latter at the expense of some computa- tional cost.



**402**                                       Real-Time Simulation Technologies

 

Finally, assumption **A4** guarantees that the observed lifetimes do not depend on the current state of the system. This allows us to use any event lifetime of an event *e* ∈ *E* that has been observed irrespective of the current state of the system and, there-

fore, to employ “event matching” as opposed to “state matching” when a constructed

sample path becomes active after being suspended for violating the (**OB**) condition.

 

**16.4.1**             **n****otation and** **d****efinitionS**

Let

x(*n*, q) = {*ej* : *j* = 1,…, *n*}

with *ej* ∈ *E*, be the sequence of events that constitute an observed sample path ω(θ) up to *n* total events. Although ξ(*n*,θ) is clearly a function of the parameter θ, we will write ξ(*n*) and adopt the notation

xˆ (*k* ) = {*e*ˆ*j* : *j* = 1,…, *k*}

for any constructed sample path under a different value of the parameter up to *k* events in that path. It is important to realize that *k* is actually a function of *n*, since the constructed sample path is coupled to the observed sample path through the observed event lifetimes. However, again for the sake of notational simplicity, we will refrain from continuously indicating this dependence.

Next, we define the *score* of an event *i* ∈ *E* in a sequence ξ(*n*), denoted by

​        

​        *i*        



*sn* = [x(*n*)]*i*, to be the nonnegative integer that counts the number of instances of



event *i* in this sequence. The corresponding score of *i* in a constructed sample path

is denoted by *s*ˆ*k* = éxˆ (*k* )ù . In what follows, all quantities with the symbol “^” above

*i*     ë     û*i*

them refer to a typical constructed sample path.

Associated with every event type *i* ∈ *E* in ξ(*n*) is a sequence of *sn* event lifetimes



​     

​        *i*        



**V***i* (*n*) = {*vi* (1),¼, *vi* (*sn* )}







for all



*i* Î*E*



 

The corresponding set of sequences in the constructed sample path is as follows:



​     

​        *i*        



**V**ˆ*i* (*k* ) = {*vi* (1),¼, *vi* (*s*ˆ*k* )}







for all





*i* Î*E*



 

which is a subsequence of **V***i*(*n*) with *k* ≤ *n*. In addition, we define the following sequence of lifetimes:



​     

​        *i*        



​        *i*        



**V** *i* (*n*, *k* ) = {*vi* (*s*ˆ*k* + 1),¼, *vi* (*sn* )}







for all





*i* Î*E*



​     

​        *i*        



which consists of all event lifetimes that are in **V***i*(*n*) but not in ***V\***ˆ (*k* ). Associated with any one of these sequences are the following operations. Given some



**W***i* = {*wi* ( *j*), ¼, *wi* (*r* )},



Concurrent Simulation for Online Optimization

 

Suffix Addition: **W***i* + {*wi*(*r* + 1)} = {*wi*(*j*), … , *wi*(*r*), *wi*(*r* + 1)} and Prefix Subtraction: **W***i* − {*wi*(*j*)} = {*wi*(*j* + 1), … , *wi*(*r*)}.



**403**



Note that the addition and subtraction operations are defined so that a new ele- ment is always added as the *last* element (the *suffix*) of a sequence, whereas subtrac- tion always removes the *first* element (the *prefix*) of the sequence. At this point, it is worth pointing out that to construct the various event lifetime sequences, it is neces- sary that the event lifetime sequences are observable from the nominal sample path. For offline approaches, this is generally simple since the lifetimes can be directly recorded from the simulator. For online approaches, this is possible for *invertible* systems, that is, systems for which event lifetimes can be recovered from the output of a system (i.e., sequence of events, states, and transition epochs) (see the work by Park and Chong14 for invertibility conditions as well as an appropriate algorithm). Next, define the set

 



​     

​        *i*        



​        *i*        



*A* (*n*, *k* ) = {*i* : *i* Î*E* , *sn* > *s*ˆ*k* }





(16.10)



 

which is associated with **V** *i* (*n*, *k* ) and consists of all events *i* whose corresponding sequence **V** *i* (*n*, *k* ) contains at least one element. Thus, every *i* ∈ *A*(*n*, *k*) is an event that has been observed in ξ(*n*) and has at least one lifetime that has yet to be used in the coupled sample path xˆ(*k*). Hence, *A*(*n*, *k*) should be thought of as the set of *avail-*

*able* events to be used in the construction of the coupled path.

Finally, we define the following set, which is crucial in our approach:

 



*M* (*n*, *k* ) = G (*x*ˆ*k* ) - (G (*x*ˆ*k* -1 ) - {*e*ˆ*k* })





(16.11)



 

where, clearly, *M*(*n*, *k*) ⊆ *E*. Note that *e*ˆ*k* is the triggering event at the (*k* − 1)th state visited in the constructed sample path. Thus, *M*(*n*, *k*) contains all the events that are in the feasible event set G (*x*ˆ*k* ) but not in G (*x*ˆ*k* -1) ; in addition, *e*ˆ*k* also belongs to *M*(*n*, *k*) if it happens that *e*ˆ*k* ÎG(*x*ˆ*k* ). Intuitively, *M*(*n*, *k*) consists of all *missing* events from the perspective of the constructed sample path when it enters a new state *x*ˆ*k* , that is, those events already in G (*x*ˆ*k* -1) that were not the triggering event remain available to

be used in the sample path construction as long as they are still feasible. All other events in the set are “missing” as far as residual lifetime information is concerned.

The concurrent sample path construction process we are interested in consists of two coupled processes, each generated by an STA as detailed in Section 16.2, through Equations 16.1 to 16.6. The observed sample path and the one to be con- structed both satisfy this set of equations. Our task is to derive an additional set of equations that captures the coupling between them. In particular, our goal is to

enable event lifetimes from the observed ξ(*n*) to be used to construct a sequence xˆ (*k* ).

First, observe that the process described by Equations 16.1 through 16.6 and applied to xˆ (*k* ) hinges on the availability of residual lifetimes *y*ˆ*i* (*k* ) for all *i* ÎG (*x*ˆ*k* ). Thus, the constructed sample path can only be “active” at state *x*ˆ*k* if every *i* ÎG (*x*ˆ*k* ) is such that either *i* Î(G (*x*ˆ*k* -1 ) - {*e*ˆ*k* }) (in which case *y*ˆ*i* (*k* ) is a residual lifetime of an event



**404**                                       Real-Time Simulation Technologies

 

available from the previous state transition) or *i* ∈ *A*(*n*, *k*) (in which case a full life- time of *i* is available from the observed sample path). This motivates the following:

 

 

**Definition** **16.1**

 

A constructed sample path is *active* at state *x*ˆ*k* after the occurrence of an observed event *en* if for every *i* ÎG (*x*ˆ*k* ), *i* Î(G (*x*ˆ*k* -1 ) - {*e*ˆ*k* }) È *A* (*n*, *k* ).

Thus, the start/stop conditions for the construction of a sample path are deter-

mined by whether it is active at the current state or not.

 

**16.4.2**             **o****bServed** **and** **C****onStruCted** **S****ample** **p****ath** **C****oupling** **d****ynamiCS**

Upon occurrence of the (*n* + 1)th observed event, *en* + 1, the first step is to update the event lifetime sequences **V** *i* (*n*, *k* ) as follows:

 



ìïV *i* (*n*, *k* ) + *vi* (*s*ˆ*n* + 1) if



*i* = *en*+1



**V** (*n* + 1, *k* ) = í             *i*



(16.12)



*i*           ïV (*n*, ***k\*** )



otherwise



î *i*

 

The addition of a new event lifetime implies that the available event set *A*(*n*, *k*) defined in Equation 16.10 may be affected. Therefore, it is updated as follows:



*A*(*n* + 1, *k* ) = *A*(*n*, *k* ) È{*en*+1}





(16.13)



 

Finally, note that the missing event set *M*(*n*, *k*) defined in Equation 16.11 remains unaffected by the occurrence of observed events:

 



*M* (*n* + 1, *k* ) = *M* (*n*, *k* )



(16.14)



 

At this point, we are able to decide whether all lifetime information to proceed with a state transition in the constructed sample path is available or not. In particular, the condition

 



*M* (*n* + 1, *k* ) Í *A*(*n* + 1, *k* )



(16.15)



 

may be used to determine whether the constructed sample path is active at the current state *x*ˆ*k* (in the sense of Definition 16.1). The following is a formal statement of this fact and is proved in the work by Cassandras and Panayiotou.4

 

**Lemma 16.1**

 

A constructed sample path is active at state *x*ˆ*k* after an observed event *en* + 1 if and only if *M*(*n* + 1, *k*) ⊆ *A*(*n* + 1, *k*).



Concurrent Simulation for Online Optimization                      **405**

​     

​        *i*        



Assuming Equation 16.15 is satisfied, Equations 16.1 through 16.6 may be used to update the state *x*ˆ*k* of the constructed sample path. In so doing, lifetimes *vi* (*sk* + 1) for all *i* ∈ *M*(*n* + 1, *k*) are used from the corresponding sequences **V** *i* (*n* + 1, *k* ). Thus, upon completion of the state update steps, all three variables associated with the coupling process, that is,V *i* (*n*, *k* ), *A*(*n*, *k*), and *M*(*n*, *k*) must be updated. In particular,





 ï**V** *i* (*n* + 1, *k* ) - *vi* (*s*ˆ*k* + 1)



for all



*i* Î*M* (*n* + 1, *k* )



**V** (*n* + 1, *k* + 1) = í                *i*



*i*             ï**V**  (*n* + 1, *k* )



otherwise



î *i*

This operation immediately affects the set *A*(*n* + 1, *k*), which is updated as follows:

​     

​        *i*        



​        *i*        



*A*(*n* + 1, *k* + 1) = *A*(*n* + 1, *k* ) - {*i* : *i* Î*M* (*n* + 1, *k* ), *s*ˆ*k* + 1 = *sn* + 1}



Finally, applying Equation 16.11 to the new state *x*ˆ*k*+1,

*M* (*n* + 1, *k* + 1) = ((*x*ˆ*k* +1 ) - (G (*x*ˆ*k* ) - {*e*ˆ*k* +1}))

 

Therefore, we are again in a position to check Equation 16.15 for the new sets *M*(*n* + 1, *k* + 1) and *A*(*n* + 1, *k* + 1). If it is satisfied, then we can proceed with one more state update on the constructed sample path; otherwise, we wait for the next

event on the observed sample path until Equation 16.15 is again satisfied. Similar to Lemma 16.1, we have the following:

 

 

**Lemma 16.2**

 

A constructed sample path is active at state *x* *k* +1 after event *e* *k* +1 if and only if

*M*(*n* + 1, *k* + 1) ⊆ *A*(*n* + 1, *k* + 1).

The analysis above can be put in the form of an algorithm termed *TWA,* which is

described next.

**Time Warping Algorithm (TWA):**

The TWA consists of three parts: an initialization, an update of the observed sys- tem state and of sample path coupling variables, and the “time warping” operation.

 

**1.**  **Initialization**

The event counts, event scores, clocks, and states of the observed and constructed sample paths are initialized in the usual way:

 



*n* = 0, *k* = 0, *s**n* = 0, *s*ˆ*k* = 0



for all



*i* Î*E* ,



*i*          *i*

*tn* = 0, *t*ˆ*k* = 0, *xn* = *x*0 , *x*ˆ*k* = *x*ˆ0



**406**                                       Real-Time Simulation Technologies

 

along with the lifetimes of the events feasible in the initial states:



*yi* (*n*) = *vi* (1)



for all



*i* ÎG (*xn* )



and the missing and available event sets:

*M* (0, 0) = G (*x*ˆ0 ),

**2.**  When Event *en* Is Observed





*A* (0, 0) = Æ



**2.1.**       

​        *i*        



Use the STA model dynamics (Equations 16.1 through 16.6) to deter- mine *en* + 1, *xn* + 1, *tn* + 1, *yi*(*n* + 1) for all *i* ÎG(*xn*+1), *s**n*+1 for all *i* ∈ *E*.



**2.2.**  Add the *en* + 1 event lifetime to **V** *i* (*n* + 1, *k* ):



ìï**V** *i* (*n*, *k* ) + *vi* (*s* *n* + 1) if



*i* = *en*+1



**V** (*n* + 1, *k* ) = í             *i*



*i*           ï**V** (*n*, *k* )



otherwise



î *i*

**2.3.**  Update the available event set *A*(*n*, *k*):

*A*(*n* + 1, *k* ) = *A*(*n*, *k* ) È{*en*+1}

**2.4.**  Update the missing event set *M*(*n*, *k*):

*M* (*n* + 1, *k* ) = *M* (*n*, *k* )

**2.5.**  If *M*(*n* + 1, *k*) ⊆ *A*(*n* + 1, *k*), then go to the time warping operation in step 3; otherwise, set *n* ← *n* + 1 and go to step 2.1.

**3.**  Time Warping Operation

**3.1.**  Obtain all missing event lifetimes to resume sample path construction at state *x*ˆ*k*

 



ìï*vi* (*s*ˆ*k* + 1)



for



*i* Î*M* (*n* + 1, *k* )



*y*ˆ (*k* ) = í    *i*



*i*      ï *y*ˆ (*k* - 1)



otherwise



î *i*

**3.2.**       

​        *i*        



Use the STA model dynamics (Equations 16.1 through 16.6) to deter- mine *e*ˆ*k* +1 , *x*ˆ*k* +1 ,*t*ˆ*k* +1 , *y*ˆ*i* (*k* + 1) for all *i* ÎG (*x*ˆ*k* +1 ) Ç (G (*x*ˆ*k* ) - {*e*ˆ*k* +1}), *s*ˆ*k* +1



for all *i* Î*E*.

**3.3.**  Discard all used event lifetimes:

​     

​        *i*        



**V** *i* (*n* + 1, *k* + 1) = **V** *i* (*n* + 1, *k* ) - *vi* (*s*ˆ*k* + 1) for all *i* Î*M* (*n* + 1, *k* )



**3.4.**  Update the available event set *A*(*n* + 1, *k*):

*A*(*n* + 1, *k* + 1) = *A*(*n* + 1, *k* ) - {*i* : *i* Î*M* (*n* + 1, *k* ), *s*ˆ*k* +1 = *sn*+1 }

*i*         *i*

**3.5.**  Update the missing event set *M*(*n* + 1, *k*):

*M* (*n* + 1, *k* + 1) = G(*x*ˆ*k* +1 ) - (G(*x*ˆ*k* ) - {*e*ˆ*k* +1})



Concurrent Simulation for Online Optimization                      **407**

 

**3.6.**  If *M*(*n* + 1, *k* + 1) ⊆ *A*(*n* + 1, *k* + 1), then set *k* ← *k* + 1 and go to step 3.1; otherwise, set *k* ← *k* + 1, *n* ← *n* + 1 and go to step 2.1.

The computational requirements of the TWA are minimal: adding and subtract- ing elements to sequences, simple arithmetic, and checking conditions (Equation 16.15). It is the storage of additional information that constitutes the major cost of the algorithm.

 

 

**Example**

 

Let us consider once again a G/G/1/*K* queueing system as in previous examples, where

the event set is *E* = {*a*, *d*} and the state space is *X* = {0, 1, … , *K*}. Let the observed sample path be one with queue capacity *K* = 2, and let us try to construct a sample path under *K* = 3 in the framework of [Figure 16.1](#_bookmark92). Let Γ(*x*[*K*]) be the feasible event set at state *x* for the system under *K* and assume that both systems are initially empty. Unlike

the SC and ASA methods, we can no longer maintain between the two sample paths (the observed one and the one to be constructed) a coupling that preserves full syn- chronization of events. This is because of the absence of Markovian event processes that allow us to exploit the memoryless property. Thus, we must maintain each feasible

event set, Γ(*x*[2]) and Γ(*x*[3]), separately for each observed state *x*[2] and constructed state *x*[3]. Whenever an event is observed, its lifetime is assumed to become available

(i.e., the time when this event was activated is known). Each such lifetime is subse- quently used in the construction of the sample path under *K* = 3.

To see precisely how this can be done, we start out with a state *x*[3] = 0 for the con-

structed sample path so that Γ(*x*[3]) = {*a*}. Since no event lifetimes are initially avail- able, we consider the sample path of this system as “suspended” with a missing event set

*M*(0, 0) = {*a*}. The initial state of the observed sample path is *x*[2] = 0 so that Γ(*x*[2]) =

{*a*}. Therefore, the first observed event is *a*. At this point, the constructed sample path may be “resumed,” since all lifetimes of the events in Γ(*x*[3]) are now available, namely, the lifetime of *a*, so we have the available event set *A*(1, 1) = {*a*}. This amounts to verify-

ing the condition *M*(1, 1) ⊆ *A*(1, 1) in step 3.6 of the TWA above. The constructed sample path advances time and updates its state to *x*[3] = 1. Now Γ(*x*[3]) = {*a*, *d*}, but neither

event has been observed yet, and therefore, the constructed sample path is suspended

again until at least one *a* and one *d* event occur at the observed sample path. This start/ stop (or suspend/resume) process goes on until a sample path under *K* = 3 is constructed up to a desired number of events or some specified time, that is, we have *M*(2, 2) =

{*a*, *d*}. In this example, assuming that both arrival and service processes have positive rates, it is clear that eventually *M*(*n* + 1, *k* + 1) ⊆ *A*(*n* + 1, *k* + 1) will be satisfied, after both an arrival event and a departure event are observed. Note that it is possible that

when an event occurs causing the condition to be satisfied, a series of events on the con- structed sample path is triggered, hence a sequence of state transitions and time updates as well. For instance, if Γ(*x*[3]) = {*a*, *d*}, a sequence of events {*a*, *a*, *a*, *d*} will cause four

state transitions in a row as soon as *d* is observed. The fact that in this process we move

backward in time to revisit a suspended sample path and then forward by one or more event occurrences lends itself to the term “time warping” in the TWA.

 

Regarding the *scalability* of the TWA, as in the case of the SC and ASA methods, it should be clear that the computational effort involved scales with the number of



**408**                                       Real-Time Simulation Technologies

 

parameters considered, *N*, and the number of values to be explored for each parameter, *Mi*, *i* = 1, … , *N*. Setting *Mi* = *M* for all *i* = 1, … , *N* for simplicity, it follows that *N* · *M* concurrent estimators are active for each simulation run. This number is a worst

case scenario. When a specific optimization problem is considered, where one can generally exploit the structure of the DES (as will be seen in the example mentioned in Section 16.5), it is possible to significantly reduce the number of active concurrent sample paths.

 

**16.4.3**             **S****peedup** **f****aCtor**

In a simulation setting, it makes sense to use concurrent simulation methods only if they can generate the required results faster than brute-force simulation. Thus, to define a speedup factor associated with a particular concurrent simulation method, suppose that the sample path constructed through such a method were instead gener- ated by a separate simulation whose length is defined by *N* total events. Let *TN* be the time it takes in Central Processor Unit (CPU) units to complete such a simulation run. Furthermore, suppose that when the nominal simulation is executed with a con-

​     

​        *N*        



​        *K*        



current simulation algorithm as part of it, the total time is given by *T o* + τ , where



​     

​        *N*        



​        *K*        



*T o* is the simulation time (with no concurrent sample path construction) and τ is the



additional time involved in the concurrent construction of a sample path with *K* ≤ *N*

events. We then define the *speedup factor* as

*S* *=* *TN* /*N*

*t**K* /*K*

Thus, when a separate simulation (in addition to the one for the observed sample path) is used to generate a sample path under a new value of the parameter of interest, the computation time per event is *TN*/*N*. If, instead, we use a concurrent simulation

method in conjunction with the observed path, no such separate simulation is neces- sary, but the additional time per event imposed by the approach is τ*K*/*K*, where *K* ≤ *N* in general. Clearly, *S* ≥ 1 is required to justify the use of concurrent simulation.

Speedup factors resulting from the use of the TWA for various queueing systems

are extensively investigated in the work by Cassandras and Panayiotou4 where the following upper bound is also derived:

 

​       

​        1        



*S* £ 1 + b - a



where α is the fraction of time used for generating random numbers and variates (0 ≤ α ≤ 1) in the nominal sample path and β = *rN*/*TN* with *rN* being the time taken to write to and read from memory in the TWA, which depends on the number of

random variates observed in the nominal sample path and used in the constructed sample path. As a rule of thumb, when we build and execute a simulation model, we can readily measure α; if (1 *−* α) is relatively small, we can immediately deduce

a potential speedup benefit through the TWA (the final result will depend on β

as well). Furthermore, the work by Cassandras and Panayiotou4 has defined the

class of *Regular DES* for which the cardinality of the missing event set |*M*(*n*, *k*)|



Concurrent Simulation for Online Optimization                      **409**

 

in Equation 16.11 is bounded by 2 with the potential to achieve higher speedups. This class includes a large family of common systems such as all open and closed Jackson-like queueing networks.3

 

 

**16.4.4**             **e****xtenSionS of the** **tWa**

To simplify the notation and presentation of the TWA, at the beginning of Section 16.4, we made four assumptions that can be relaxed and still make TWA applicable. In **A1**, we assumed that that the nominal sample path will never go into an absorb-

ing state, or a set of states, for which an event *e* ∈ *E* will never become feasible at any time in the future. This may freeze indefinitely the construction of one or more

concurrent sample paths since such a sample path may have *e* in its missing event set; however, *e* will never occur in the future. In situations such as this, assuming some knowledge of the event lifetime distributions, one can use a random number gen- erator to generate the required event lifetimes, thus allowing the construction of all constructed sample paths. A similar situation may arise when an event occurs rarely, which may force the construction of all concurrent sample paths to be suspended waiting for the occurrence of the rare event. In this case, a possible policy would be to use a random number generator to obtain the required lifetime if a constructed sample path is suspended for more than a certain number of observed events.

In **A2**, we assumed that changing a parameter from θ0 to some θ ≠ θ0 does not alter the event set *E*. Clearly, if the new event set *Em* is such that *Em* ⊆ *E*, the develop- ment and analysis of TWA is not affected. If, on the contrary, *E* ⊂ *Em*, this implies that events required to cause state transitions under θ*m* are unavailable in the observed sample path, which make the application of our algorithm impossible. Notice the

similarity of this problem with the one discussed above. In this case, one can intro- duce *phantom* event sources that generate all the unavailable events as described, for example, in the work by Cassandras and Shi,15 provided that the lifetime distribu- tions of these events are known.

​     

​        *i*        



In **A3**, we assumed that changing a parameter from θ0 to some θ*m* ≠ θ0 does not affect the distribution of one or more event lifetime sequences. This assumption is used in Equation 16.12 where the observed lifetime *vi* (*sn* + 1) is directly suffix-added to the sequence **V** *i* (*n* + 1, *k* ). Note that this problem can be overcome by transform- ing observed lifetimes **V***i* = {*vi*(1), *vi*(2), …} with an underlying distribution *Gi*(θ0) into samples of a similar sequence corresponding to the new distribution *Gi*(θ*m*) and then suffix-add them in **V** (*n* + 1, *k* ). This is indeed possible, if *Gi*(θ0), *Gi*(θ*m*) are known, at the expense of some additional computational cost for this transformation



(e.g., see the work by Cassandras and Lafortune3). One interesting special case arises when the parameter of interest is a scale parameter of some event lifetime distribution (e.g., it is the mean of a distribution in the Erlang family). Then, simple

rescaling suffices to transform an observed lifetime *vi* under θ0 into a new lifetime

*v* *i* under θ*m*:

 

*v* *i* = (q*m* /q0 ) *vi*



**410**                                       Real-Time Simulation Technologies

 

Finally, in principle, one can also relax assumption **A4** and record all observed lifetimes not only based on the associated event but also based on the state in which they have been activated. Computationally, this is feasible. However, depending on the state spaces of the nominal and constructed sample paths, it is likely that the aforementioned “tricks” with *phantom* event sources will be required more frequently. A similar situation may arise if the underlying STA allows probabilistic state transition mechanisms. In this case, the state transitions should also be recorded on a per-state basis unless the state transition mechanism has a structure that can be exploited such that “event matching” is again adequate. For example, consider a sys- tem with two parallel FIFO queues with infinite capacity where an arriving customer

enters queue 1 with probability *p* or queue 2 with probability 1 − *p*. Let (*x*1, *x*2) denote the state of the system where *xi*, *i* ∈ {1, 2} is the length of each queue. In the event of a customer arrival, the new state will become (*x*1 + 1, *x*2) with probability *p* and (*x*1, *x*2 + 1) with probability 1 − *p*. In this case, the state transition probabilities have a structure that is independent of the current state; thus, one can exploit this and use

the observed outcomes irrespective of the current state. Consequently, event match- ing is no longer necessary.

[16.3 <--- ](16_3.md) [   Зміст   ](README.md) [--> 16.5](16_5.md)