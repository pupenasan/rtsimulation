[16.4 <--- ](16_4.md) [   Зміст   ](README.md) [--> 16.6](16_6.md)

## 16.5. USE OF TWA FOR REAL-TIME OPTIMIZATION

In this section, we present an example where the TWA is used together with a real- time controller that controls the buffers allocated to different processes. Specifically, we consider the system shown in Figure 16.3 where customers arrive according to some distribution *Ga*(·) (generally unknown and possibly time varying) and are probabilistically routed to one of the *S* available servers. The routing probabilities *pi*(*t*),

*i* = 1, … , *S*, may also be unknown and time varying. Each customer, once assigned to a server, immediately proceeds to the corresponding finite capacity queue where,

if there is available space, it waits using a FIFO discipline to receive service from the server. If no buffering space is available, the customer is considered blocked. Furthermore, the time taken to service a customer at server *i* is according to some

 

 

​                                                                                                                                        

​            µ1      1            

​            *a*            

​            µ2      2            

​            ·            

​            µ*s*      *S*            







 

**FIGURE 16.3** Queueing system with *S* parallel servers.



Concurrent Simulation for Online Optimization                      **411**

distribution *Gd,i*(·), *i* = 1, … , *S*. In this context, we assume that there are *K* available buffers that must be allocated to the *S* servers (and can be freely reallocated to any

server) to minimize some metric such as the blocking probability (the probability that a customer that is assigned to a server will find the corresponding buffer full). In other words, we are interested in solving the following optimization problem:



 

​     

​        å   (  )*i*   *i*             *i*        



*S*



min   b *J n*

qÎQ *i*=1



 

s.t.



 

​     

​        *S*        





​                             





å*ni* = *K*

*i*=1



 

(16.16)



 

where 1 ≤ *ni* ≤ *K* − *S* + 1 is the number of buffer units assigned to server *i*, *Ji*(*ni*) is the blocking probability at queue *i* when allocated *ni* buffer units, **θ** = [*n*1, … , *ns*] is an allocation vector and Θ is the set of all feasible allocation vectors. Finally, β*i* is a weight associated with server *i*, but for simplicity, we will assume β*i* = 1 for all *i*.

Typically, one is interested in solving Equation 16.16 when *Ji*(*ni*) is of the form of an expectation *Ji*(*ni*) = *E* [*Li*(*ni*, ω(*ni*, [*T*1, *T*2]))] where *Li*(*ni*, ω(*ni*, [*T*1, *T*2])) is a sample blocking probability observed at the system during the interval [*T*1, *T*2]. In general,

there exists no closed-form solution for *Ji*(*ni*) unless the system is driven by Poisson arrivals and exponential service times, all with known rates as well as known routing probabilities. Thus, a possible approach to solve this problem is to make an initial

allocation θ0 and observe the sample path of the system over the interval [0, *T* ] (where *T* is a predefined period). Using the information extracted from the observed sample path, one can compute the sample performance metrics *Li*(·), *i* = 1, … , *S* for the allocation θ0 and use TWA to construct the sample paths for all other allocations θ ∈ Θ − {θ0} and from them compute the corresponding sample performance functions. Consequently, at *t* = *T*, the controller can determine the allocation

q* = argmin *L* (q)

qÎQ

 

where

 



 

​     

​        *S*        









*L* (q) = å *Li* (*ni* ,w(*ni* , [0,*T* ])),

*i*=1



q = [*n*1,¼, *nS* ] ÎQ



Before proceeding any further, it is instructive to comment on an underlying assumption and two important parameters of the proposed optimization approach, namely, the length of the observation interval *T* and the cardinality of the set Θ. Note

that the optimization approach uses data collected in the interval [0, *T*] to make

buffer assignments that will be valid for *t* > *T* or, more precisely, for the interval [*T*, 2*T*]. Thus, the underlying assumption is that the future behavior of the system

will be very similar to its past behavior. In other words, this approach is applicable to systems where the input stochastic processes that drive the system dynamics (in this example, the routing probabilities *pi*(*t*), *i* = 1, … , *S*) change slowly compared to the

observation interval *T*. Regarding the observation interval, its actual value depends

on the variance of the input and output stochastic processes. If set too short, then the obtained performance metrics may be too noisy and, as a result, the controller may



**412**                                       Real-Time Simulation Technologies

 

pick random allocations. On the contrary, *T* should not be set too large because the underlying assumption mentioned earlier may not be valid: if *T* is set too large and the behavior of the system has changed over time, then this will not be detected fast enough, and thus, the system may continue to operate at suboptimal allocations.

Regarding the cardinality of Θ, one can easily notice that it can become very large, which may cause computational problems due to the large number of sample paths

that must be constructed. For the above example, the number of feasible allocations

is *O* æ (*K* + *S* 1)!ö. To alleviate the computational problem, one may resort to various

 ç *K* !(*S* 1)! ÷ø

optimization approaches taking advantage of some properties of the cost function. For the above example, we know that *Ji*(*ni*) is decreasing and convex; thus, one may use “gradient”-based optimization approaches. In this case, we use finite differences together with a discrete resource allocation approach,16 which is briefly summarized

below to reduce the number of constructed sample paths from *O* æ (*K* + *S* 1)!ö

 ç *K* !(*S* 1)! ÷ø

to only *S* + 2. The idea of the discrete optimization approach is rather simple: at every step, it reallocates a resource (buffer) from the least “sensitive” server to the

most sensitive one where sensitivity is defined as

 



D*Li* (*ni* ) = *Li* (*ni* ) *Li* (*ni* 1),



*ni* = 1,¼, *K*



(16.17)



 

Below are the detailed steps of the algorithm: Algorithm: *Dynamic Resource Allocation*

 

​     

​        1        



​        *S*        



​        *S*    *S*        



**1.0** Initialize: q0 = éë*n*(*o*) ,¼, *n*(0) ùû;*C*(0) = {1,¼, *S*}; *k* = 0





​     

​        1        



​        *S*        



​        1     1        



**1.1** Evaluate **D**(*k* ) (*n*(*k*) ,¼, *n*(*k*) ) º éëD*L* (*n*(*k*) ),¼, D*L*





(*n*(*k* ) )ùû



**2.1** Set *i** = argmax     (*k* ) éë**D**(*k* ) (*n*( ) ,¼, *n* )ùû

​     

​        *i*=1,¼,*C*        



*k*         (*k* )



​     

​        1        





​	                    *S*                 



**2.2** Set *j** = argmin (*k* ) éë**D**(*k* ) (*n*( ) ,¼, *n* )ùû

*k*         (*k* )

​     

​        *i*Î*C*        





​	                    1                                      *S*                 



​     

​        1        



​        *i*        



​        *j**        



​        *S*        



**2.3** Evaluate **D**(*k* ) (*n*(*k*) ,¼, *n*(*k*) + 1,¼, *n*(*k*) 1,¼, *n*(*k*) )



**2.4** If D*L* * (*n*(*k*) 1) < D*L* * (*n*(*k*) ) Goto **3.1** ELSE Goto **3.2**

*j*     *j**                            *i*     *i**

**3.1**   Update allocation:

 

*n*(*k*+1) = *n*(*k*) + 1; *n*(*k*+1) = *n*(*k*) 1; *n*(*k* +1) = *n*(*k* ) for all *m* Î*C*(*k* ) and



*i**                  *i**



*j**                  *j**                 *m*         *m*



*m* ¹ *i** , *j**; Set *k* ¬ *k* + 1

Reset *C*(*k*) = {1,¼, *S*},and Goto **2.1**

**3.2**   Replace *C*(*k*) by *C*(*k*) − {*j**};

IF |*C*(*k*)| = 1, Reset *C*(*k*) = {1, … , *S*}, and Goto **2.1**

ELSE Goto **2.2**



Concurrent Simulation for Online Optimization                      **413**

 

When the system operates under a nominal allocation, one can obtain estimates of *Li*(*ni*) while concurrent estimators can provide estimates for *Li*(*ni* − 1); thus, the vector **D**(k) (·) with all finite differences can be computed in step 1.1. Steps 2.1 and 2.2

determine the servers with the maximum and minimum finite differences *i**** and *j****, respectively. Step 2.3 reevaluates the finite differences after a resource is reallocated from the least sensitive *j**** to the most sensitive *i****. If the removal of the resource does not make *j**** the most sensitive buffer, the reallocation is accepted in step 3.1, otherwise it is rejected in step 3.2.

Next, we consider a numerical example with *S* = 4 and *K* = 16. We assume that the arrival process is Poisson with rate λ = 1.3, and all service times (at any server) are exponential with rates µ*i* = 1.0 for all *i* = 1, … , 4. At this point, we emphasize that the controller does not know anything about either the arrival or the service

processes. Furthermore, we assume that the routing probabilities are also unknown to the controller and are time varying. Specifically, the routing probabilities change every 50,000 time units as given in Table 16.1.

[Figure 16.4 ](#_bookmark94)presents the performance (loss probability) of the real-time controller (i.e., the dynamic resource allocation algorithm) in comparison to a static policy. Because of symmetry, the static optimal allocation is [4, 4, 4, 4], which achieves a loss probability between 0.08 and 0.1 for the entire simulation interval. As shown in the figure, the real-time controller can significantly improve the overall system performance since the real-time simulation components can “detect” the overloaded buffer and allocate more resources to it, thus reducing the overall loss probability. Initially, the controller adjusts the buffers such that the loss probability is between

0.02 and 0.04. At time 0.5 × 105, the routing probabilities change abruptly, and thus, the loss probability significantly increases; however, as seen in the figure, the

real-time controller quickly reallocates the buffers and the loss probability is again reduced. Similar behavior occurs every time the routing probabilities change.

In [Figure 16.5](#_bookmark94), we also investigate the effect of the observation interval. The scenario investigated is identical to the one presented earlier. The only difference is the length of the observation interval *T*. In this experiment, we assume that the controller updates the allocation vector every *NT* observed events (here we use *NT* instead of *T* to indicate that the interval is determined by the number of events rather than time units). The figure presents the results for three different values of *NT*. As indicated

in the figure, when *NT* is too large (*NT* = 7000), the controller does not capture the change in the routing probabilities, and as a result, it leaves the system operating

 

 

| **TABLE** **16.1**  **Routing** **Probabilities** |         |                               |
| ------------------------------------------------- | ------- | ----------------------------- |
| **From**                                          | **To**  | **Distribution**              |
| 0                                                 | 50,000  | **p**1 = [0.7, 0.1, 0.1, 0.1] |
| 50,000                                            | 100,000 | **p**2 = [0.1, 0.7, 0.1, 0.1] |
| 100,000                                           | 150,000 | **p**3 = [0.1, 0.1, 0.7, 0.1] |
| 150,000                                           | 200,000 | **p**4 = [0.1, 0.1, 0.1, 0.7] |



**414**                                       Real-Time Simulation Technologies

 

​                                                                                                       

​          Fixed allocation Dynamic allocation          



0.12



 

0.11

 

0.1

 

0.09

 

​     ![Підпис: Loss probability](file:///C:/Users/OLEKSA~1/AppData/Local/Temp/msohtmlclip1/01/clip_image001.png)0.08

 

0.07

 

0.06

 

0.05

 

0.04

 

0.03

 

​     

​                         0.2                  0.4                  0.6                  0.8        1                  1.2                  1.4                  1.6                  1.8       2                                                                                     Time units                                                                           × 105                            



0.020



 

**FIGURE 16.4** System performance under the *dynamic* allocation scheme versus a *fixed*

resource allocation vector.

 

​                                                                                                     

​          *NT* = 7000 Events *NT* = 1000 Events *NT* = 166 Events          



0.2



 

0.18

 

0.16

 

0.14

 

​     ![Підпис: Loss probability](file:///C:/Users/OLEKSA~1/AppData/Local/Temp/msohtmlclip1/01/clip_image002.png)0.12

 

0.1

 

0.08

 

0.06

 

0.04

 

0.02

 

​                       

​                         0.2                  0.4                  0.6                  0.8       1                  1.2                  1.4                  1.6                  1.8       2                                                                                     Time units                                                                           × 105                            



0 0



 

**FIGURE 16.5** System performance under different observation intervals.



Concurrent Simulation for Online Optimization                      **415**

 

at suboptimal allocations for long periods of time seriously degrading the overall system performance. On the contrary, when the observation interval is fairly short (*NT* = 166), the obtained estimates are fairly noisy, and as a result, the controller

often makes “wrong” decisions, which also leads to poor performance.

[16.4 <--- ](16_4.md) [   Зміст   ](README.md) [--> 16.6](16_6.md)