[17.1 <--- ](17_1.md) [   Зміст   ](README.md) [--> 17.3](17_3.md)

## 17.2. BACKGROUND

In general, large-scale distributed systems are difficult to validate. Though some simulators, such as USSF described in Section 17.2, can emulate networks consisting of millions of nodes, simulation technologies that scale to this level often deviate from the performance and characteristics of target large-scale systems. This section describes related work on validating distributed systems and summarizes the pros and cons of current validation techniques with respect to their ability to address the role of time dilation in large-scale system validation. We divide related background material into two main areas: formal composition and simulation techniques.

Загалом, великомасштабні розподілені системи важко перевірити. Хоча деякі симулятори, такі як USSF, описані в розділі 17.2, можуть емулювати мережі, що складаються з мільйонів вузлів, технології моделювання, які масштабуються до цього рівня, часто відрізняються від продуктивності та характеристик цільових великомасштабних систем. У цьому розділі описується пов’язана робота з перевірки розподілених систем і підсумовуються плюси та мінуси поточних методів перевірки щодо їх здатності розглядати роль затримки часу у великомасштабній перевірці системи. Ми поділяємо відповідний довідковий матеріал на дві основні області: формальна композиція та методи моделювання.

### 17.2.1 Formal Composition Techniques

Formal composition is typically associated with modeling a target system in a computer-aided manner that ensures the distributed system is validated based on validated components and will execute properly on the target system [7]. When constructing mission and safety-critical distributed real time and embedded systems, such as flight avionics computers and nuclear power plant control systems, software developers often use formal composition techniques and tools, such as Step- Wise Refinement [8], Causal Semantics [9], Behavioral Modeling [10], and Object Modeling Technique [7], to validate their software before it goes into production.

Формальна композиція, як правило, пов’язана з моделюванням цільової системи за допомогою комп’ютера, що забезпечує перевірку розподіленої системи на основі перевірених компонентів і її належне виконання в цільовій системі [7]. При побудові критично важливих для безпеки розподілених систем реального часу та вбудованих систем, таких як комп’ютери авіоніки польоту та системи керування атомними електростанціями, розробники програмного забезпечення часто використовують методи й інструменти формальної композиції, такі як Step-Wise Refinement [8], Causal Semantics [9]. ], Behavioral Modeling [10] і Object Modeling Technique [7], щоб перевірити їхнє програмне забезпечення перед його запуском у виробництво.

Formal composition techniques are often time consuming to validate, however, and can be tightly coupled to a particular development context and domain. Moreover, many formal composition methods require developers to model *everything* (e.g., from processors to operating systems to the application logic) to validate the target system. When composing systems-of-systems with formal composition techniques in this manner, it is difficult to ensure a meaningful composition of heterogeneous components that interoperate correctly [11]. Progress is being made in this area of expertise–including a recent Turing Award awarded to Edmund Clarke, Allen Emerson, and Joseph Sifakis in 2007 for their work in the field of model checking [12], but formal composition of heterogeneous hardware, software, and platforms generally remains an open challenge, especially for large-scale distributed systems. The main thrust of current development in this area of expertise is the domain- specific modeling language (DSML) [13], which requires developers to tailor a visual modeling language to a specific knowledge domain, allowing business logic programmers to create an application, device driver, etc. for a specific application need (e.g., a device driver for a particular type of hardware). DSMLs can shield developers from many tedious and error-prone hardware and operating system concerns, allowing them to focus on modeling the business application logic and allow further validation by tools developed by researchers and engineers experienced in the target domain.

Однак методи формальної композиції часто потребують багато часу для перевірки, і вони можуть бути тісно пов’язані з конкретним контекстом розробки та доменом. Крім того, багато формальних методів композиції вимагають від розробників моделювання *все* (наприклад, від процесорів до операційних систем і логіки додатків) для перевірки цільової системи. При компонуванні системи систем за допомогою методів формальної композиції таким чином важко забезпечити значущу композицію різнорідних компонентів, які правильно взаємодіють [11]. Прогрес досягається в цій галузі знань, включаючи нещодавню нагороду Тюрінга, присуджену Едмунду Кларку, Аллену Емерсону та Джозефу Сіфакісу в 2007 році за їхню роботу в галузі перевірки моделей [12], але формальний склад різнорідного обладнання, програмного забезпечення, і платформ загалом залишається відкритим викликом, особливо для великомасштабних розподілених систем. Основним напрямом поточного розвитку в цій галузі знань є предметно-орієнтована мова моделювання (DSML) [13], яка вимагає від розробників адаптувати мову візуального моделювання до певної області знань, дозволяючи програмістам бізнес-логіки створювати програму, пристрій драйвер тощо для потреб певної програми (наприклад, драйвер пристрою для певного типу обладнання). DSML може захистити розробників від багатьох виснажливих і схильних до помилок апаратних і операційних систем, дозволяючи їм зосередитися на моделюванні логіки бізнес-додатків і дозволити подальшу перевірку за допомогою інструментів, розроблених дослідниками та інженерами, які мають досвід роботи в цільовій області.

Though DSMLs can simplify validation of certain software/hardware artifacts (such as device drivers on an airplane) for application developers, it is much more difficult to make a DSML that encompasses all hardware, device drivers, operating systems, etc. for an Internet-connected application or even a small network of application processes. One issue that hinders modeling languages from being able to completely validate arbitrary application and infrastructure software is the sheer variety of orthogonal personal computer architectures and configurations that must be expressed to ensure proper validation.

Хоча DSML може спростити перевірку певних артефактів програмного/апаратного забезпечення (наприклад, драйверів пристроїв у літаку) для розробників додатків, набагато складніше створити DSML, який охоплює все апаратне забезпечення, драйвери пристроїв, операційні системи тощо для Інтернету. підключена програма або навіть невелика мережа процесів програми. Однією з проблем, яка заважає мовам моделювання повністю перевірити довільне програмне забезпечення та інфраструктуру, є різноманітність ортогональних архітектур персональних комп’ютерів і конфігурацій, які повинні бути виражені для забезпечення належної перевірки.

Validating an application can be simplified somewhat for homogenous configurations (e.g., all personal computers are Dell T310 with a certain number and type of processors, all running a specific version and configuration of Windows, etc.), but complexities remain because of randomized algorithms used in many components of operating systems such as page replacement and queuing. Threading presents additional challenges, even in homogonous hardware configurations, since composing multiple threads has no formally recognized semantic definition that fits all possible compositions [11].

Перевірку програми можна дещо спростити для однорідних конфігурацій (наприклад, усі персональні комп’ютери Dell T310 із певною кількістю та типом процесорів, на всіх працює певна версія та конфігурація Windows тощо), але складності залишаються через використання рандомізованих алгоритмів. у багатьох компонентах операційних систем, таких як заміна сторінок і черги. Потоковість представляє додаткові проблеми, навіть в однорідних апаратних конфігураціях, оскільки створення кількох потоків не має формально визнаного семантичного визначення, яке б відповідало всім можливим композиціям [11].

When heterogeneous hardware, operating systems, and software must be supported, validating software with formal composition techniques becomes even harder. Formally composing legacy systems with closed-source implementations into a large-scale system may be aided by solutions that allow descriptions of behaviors by the legacy system, but it is still difficult to ensure that an entire large-scale system is formally composed in a semantically meaningful way. Because of these issues, we do not discuss formal composition techniques in this chapter, but instead focus on a separate vector of validation: simulation.

Коли необхідно підтримувати різнорідне апаратне забезпечення, операційні системи та програмне забезпечення, перевірка програмного забезпечення за допомогою методів формальної композиції стає ще складнішою. Офіційному створенню застарілих систем із закритими реалізаціями у великомасштабну систему можуть допомогти рішення, які дозволяють описувати поведінку застарілої системи, але все ще важко гарантувати, що вся великомасштабна система формально скомпонована в семантично осмислений спосіб. Через ці проблеми ми не обговорюємо методи формальної композиції в цій главі, а натомість зосередимося на окремому векторі перевірки: моделюванні.

### 17.2.2 Simulation Techniques

Simulation is the process of reproducing the conditions of a target platform [14], and because of its flexibility, simulation has been the de facto method for validating many networked and distributed applications. A popular simulation model is discrete event simulation, where business application logic, operating system logic, etc. are treated as distinct, discrete events that are processed by a simulator engine [15,16,17,18]. Though simulation has evolved quite a bit in recent decades, simulators often make approximations that bring testing closer to a target system but do not precisely match what is being simulated, especially when the network connectivity, processing elements, or activities performed that are being simulated experience failures, intermittent behavior, or scarce resources.

Моделювання — це процес відтворення умов цільової платформи [14], і завдяки своїй гнучкості моделювання було фактичним методом перевірки багатьох мережевих і розподілених програм. Популярною симуляційною моделлю є моделювання дискретних подій, де логіка бізнес-додатків, логіка операційної системи тощо розглядаються як окремі, дискретні події, які обробляються механізмом симулятора [15,16,17,18]. Незважаючи на те, що симуляція значно розвинулася за останні десятиліття, симулятори часто роблять наближення, які наближають тестування до цільової системи, але не відповідають точно тому, що моделюється, особливо коли мережеве з’єднання, елементи обробки або дії, що виконуються, моделюються. невдачі, переривчаста поведінка або дефіцит ресурсів.

Simulation technologies are particularly problematic in highly connected distributed or networked applications where Internet connections with high failure rates or resends are frequent. Although simulating the Internet is generally considered infeasible [19,20], many network emulators exist that attempt to emulate Internet access times, intermittency, network congestion, etc., and local area network testing. Examples of these simulators include Emulab and its derivatives Netlab [21] and ISIS Lab at Vanderbilt University [22], which can simulate dozens to hundreds of processing elements and their interconnections.

Технології моделювання є особливо проблематичними в розподілених або мережевих програмах із високим рівнем зв’язку, де часто виникають підключення до Інтернету з високим рівнем відмов або повторних відправлень. Хоча симуляція Інтернету зазвичай вважається неможливою [19,20], існує багато мережевих емуляторів, які намагаються імітувати час доступу до Інтернету, переривчастість, перевантаження мережі тощо, а також тестування локальної мережі. Приклади таких симуляторів включають Emulab та його похідні Netlab [21] і ISIS Lab в Університеті Вандербільта [22], які можуть симулювати від десятків до сотень елементів обробки та їхніх взаємозв’язків.

Emulab and its derivatives allow swapping in operating system images, applications, and test script setup to enable automated testing. They also provide robust network emulation including bandwidth restriction, packet loss, etc. Accuracy of the simulation is left as an exercise to the developer or user and how they configure operating system images, scripts, etc. Moreover, Emulab does not explicitly support multiple VMs per host, though if a user must scale a small testbed to a larger target system, operating system–specific VM managers, such as Xen [23], may be used.

Emulab та його похідні дозволяють замінювати образи операційної системи, програми та налаштування сценарію тестування для автоматизованого тестування. Вони також забезпечують надійну емуляцію мережі, включаючи обмеження пропускної здатності, втрату пакетів тощо. Точність моделювання залишається розробником або користувачем як вправа, а також як вони налаштовують образи операційної системи, сценарії тощо. Крім того, Emulab явно не підтримує кілька віртуальних машин. на хост, хоча, якщо користувачеві необхідно масштабувати невеликий тестовий стенд до більшої цільової системи, можна використовувати спеціальні менеджери віртуальних машин, такі як Xen [23].

Other simulators such as Modelnet [24] and USSF [19] enable explicit virtualization of hosts and also include robust network emulators. Modelnet separates a testbed infrastructure into edge nodes and nodes that act as switches between the edge nodes. Vahdat et al. [24] showed that a host emulating Gigabit Ethernet in Modelnet can result in approximations of networked application performance during simulation. The throughput difference between the emulation and real-world performance shown in their results, however, can differ by as much as 20%. Closer performance is possible if more than just networking is emulated, as shown in Section 17.4, via time dilation. USSF is a simulation technology based on Time Warp and built on top of the WARPED [25] parallel discrete-event simulator that claims to simulate large-scale target systems of over 100,000 nodes [26]. USSF is complicated to use and develop for, requiring the creation of topology models and generation from application model to application code. Developers then tailor their application to the simulator, which may be unacceptable for existing code, particularly complex code that interfaces with undocumented legacy systems.

Інші симулятори, такі як Modelnet [24] і USSF [19], дозволяють явну віртуалізацію хостів, а також включають надійні емулятори мережі. Modelnet розділяє інфраструктуру тестового стенда на граничні вузли та вузли, які діють як комутатори між граничними вузлами. Вахдат та ін. [24] показав, що хост, який емулює Gigabit Ethernet у Modelnet, може призвести до наближення продуктивності мережевих додатків під час моделювання. Однак різниця в пропускній здатності між емуляцією та реальною продуктивністю, показана в їхніх результатах, може відрізнятися на 20%. Більш висока продуктивність можлива, якщо емулювати більше, ніж просто мережу, як показано в розділі 17.4, через уповільнення часу. USSF — це технологія моделювання, заснована на Time Warp і створена на основі WARPED [25] паралельного симулятора дискретних подій, який стверджує, що моделює великомасштабні цільові системи з понад 100 000 вузлів [26]. USSF складно використовувати та розробляти, вимагаючи створення моделей топології та генерації від моделі програми до коду програми. Потім розробники адаптують свою програму до симулятора, що може бути неприйнятним для існуючого коду, особливо складного коду, який взаємодіє з недокументованими застарілими системами.

Working with USSF requires parsing a USSF model into a Topology Specification Language and then code generation via static analysis to reduce memory consumption—a major issue in WARPED libraries. The resulting code then links to WARPED libraries and the USSF kernel, which interfaces to the user application. Although USSF does allow simulation of potentially millions of nodes, there is no guarantee (or even an established working estimate) that the simulation will match a physical target system because USSF development has been prioritized to operate on reduced memory per VM, high cache hit ratios via file-based caching with a least-recently-used policy for cache replacement, etc. and not accuracy of simulation.

Робота з USSF вимагає синтаксичного аналізу моделі USSF на мову специфікації топології, а потім генерації коду за допомогою статичного аналізу, щоб зменшити споживання пам’яті — головна проблема в бібліотеках WARPED. Потім отриманий код посилається на бібліотеки WARPED і ядро USSF, яке взаємодіє з програмою користувача. Незважаючи на те, що USSF дозволяє симулювати потенційно мільйони вузлів, немає гарантії (або навіть встановленої робочої оцінки), що симуляція відповідатиме фізичній цільовій системі, оскільки розробка USSF була спрямована на роботу зі зменшеною пам’яттю на віртуальну машину та високим коефіцієнтом попадання кешу. через кешування на основі файлів із політикою найменшого використання для заміни кешу тощо, а не точністю моделювання.

[17.1 <--- ](17_1.md) [   Зміст   ](README.md) [--> 17.3](17_3.md)