[20.2 <--- ](20_2.md) [   Зміст   ](README.md) [--> 20.4](20_4.md)

**20.1**            **ACHIEVING RT IN ENGINE SIMULATION**

This section shows the tasks and challenges in practical RT modeling of automotive systems. Like a passenger vehicle, the combustion engine is a complex multiphysics system in its own right. Without neglecting generality, this section focuses on the modeling of combustion engines, particularly their crucial intake/exhaust gas and fuel subsystems.

 

**20.3.1**             **C****hoosing** **the** **R****ight** **t****ype** **of** **M****odel**

There are a considerable number of approaches to modeling combustion engines, but just a few are amenable to RT applications. A physical formulation of the dynamics will be stressed because of its superior properties in terms of its ability

 

\1.   To extrapolate into regions where no measurements are available

\2.   To reuse models and parameters

\3.   To reduce the effort required for parameterization

\4.   To immediately understand the modeled phenomena

 

In this section, black-box approaches such as neural networks or model order reduction are considered a complement to PDE- or ODE-based methods (Meder et al. 2007). The number of domains involved is considerable, leading to a heterogeneous physical description and rich dynamics of the complete system. That is why most resulting models are either restricted to being a single domain model or a hybrid of both black-box and physical formulation, often resulting in gray-box models.

Among the most complicated, and also most interesting, dynamics in an automotive system may be the gas-exchange phenomena during a working cycle in the cylinder and the intake air and exhaust paths. Turbulent flows of multiphase media within complex geometries, heat transfer, and intricate chemical reactions, for example, during combustion, call for CFD models because of their resolution capabilities in time and space (Chung 2003). These models, however, are still far from being RT capable on standard hardware, for example, FIRE (AVL FIRE 2006), mainly because of the discretization in two or three dimensions. Classical methods of order reduction or the usage of neural networks with a focus on control theory are sometimes applied to reduce complexity. Papadimitriou, for example, shows a method to transform complex one-dimensional flow models into an RT neural network model of a combustion engine (Papadimitriou et al. 2005).

A more physical way of reducing the complexity of PDE solutions is the use of modal and lumped formulations of the dynamics in which symmetries are exploited or assumed. The engine cycle calculation (ECC) partitions gas volumes into ideally mixed finite volumes and ends up with a set of coupled ODEs that are solved while satisfying the conservation laws, as shown in Merker et al. (2006). The technical analogy is a set of plenums or coolers coupled by nozzles. The very complex and nonequilibrium aspects such as heat release rate and heat transfer are augmented as parametric or semiphysical models (see, e.g., Vibe [1970]) that allow for the adaptation of the model to varying operating points. An investigation of the eigenfrequencies



Automotive Real-Time Simulation                               **507**

 

of these models reveals that typical sampling rates must lie in the order of magnitude of 100 kHz to obtain realistic results for, for example, the in-cylinder pressure of a high-rev gasoline engine. Especially, the heat transfer to the cylinder walls, the piston, and the cylinder head is treated usually by empirical models as this process is much too complex to model from first principles. A more realistic modeling of a direct injection combustion process or the formation of engine emissions can be approximated within the ECC. The cylinder volume then has to be partitioned into two to several hundred coupled zones (Heywood 1989). The ECC is a powerful method offering a wide range of application. Common applications are development of control strategies, sensitivity analysis, combustion process development, and ECU testing. The computational complexity is at the limits of current processor power providing cause to the emergence of commercial RT models (DYNA4Engine 2009; ASM InCylinder 2006).

Mean value engine models (MVEMs) are a classical way of modeling the processes inside the combustion engine. Similar to ECC, these are based on a DAE/ ODE formulation, but the physical states are considered within a more macroscopic time scale. States are considered mean values with respect to a time range of three to five engine revolutions (Jensen et al. 1991). This is sufficient to model fast changing processes such as the opening of the exhaust gas recirculation (EGR) valve. Desired states are engine speed, engine torque, and manifold pressure to name just a few. In terms of complexity and computational effort, they rank below the ECC (Hendricks and Sorenson 1990). For the description of engine phenomena that are too complex for modeling the physics from first principles, dependent and independent variables are separated to be able to employ simple empirical models or mapped data from measurements (Jensen et al. 1991). The strength of MVEMs lies in their ability to be easily adapted to other engines. Their compact mathematical formulation requires only a comparably small number of parameters and can be calibrated to a particular engine with a small set of measurements (Hendricks and Sorenson 1990). MVEMs are often utilized in the development of control strategies and in model-based diagnostics. See Section 20.4 for some HIL applications.

State-free approaches such as engine torque maps represent a simple way to model engine behavior. These are very popular, especially in ECU applications, because they are computationally robust and efficient while offering fairly high accuracy if using data obtained by (often relatively few) engine measurements. On the other hand, maps are almost ruled out for modeling transient behavior accurately (Gheorghiu 1996), and they can potentially introduce undesired nonlinearities into the dynamics of a controlled system.

In the end, the purpose of RT engine simulation is to deliver a system’s response with respect to time that is physically correct and free of contradictions. Therefore, the choice of an appropriate model for a specific investigation or task is an intricate trade-off between available computing power, required sample rates and response times, and validity of the modeled dynamics. [Figure 20.2 ](#_bookmark119)relates the computational complexity to time scales of characteristic phenomena in engine modeling. The gray area depicts the region of applications currently possible on standard processing hardware.



**508**                             Real-Time Simulation Technologies

 

 



 

2D/3D

models

 

​        ![Підпис: Log(computing time)](file:///C:/Users/OLEKSA~1/AppData/Local/Temp/msohtmlclip1/01/clip_image001.png)1D and multizone models





Real-time capability





CFD

 

​                                 ECC



 



0D physical models

 

0D semiphysical or parametric models

 

Nonparametric models





 

MVEM

 

Map-based model, neural networks



 

Turbulence     Crank angle Engine cycle Steady state

Characteristic phenomenon (corresponds to time scale)

**FIGURE 20.2** Relationship between engine model complexity and modeled phenomena.

 

 

**20.3.2**              **d****ata** **p****RepaRation**

As pointed out in Section 20.2, a model of the dynamics of a technical system is composed of (1) a description of the physical behavior, (2) model parameters *p*, and

(3)   initial conditions. In order for a model to be able to sufficiently replace the physical component of a system, it is imperative that the data used are sufficiently precise and correct. Insufficient care while preparing model data or modeling will almost certainly lead to erroneous simulation results. Furthermore, data preparation takes a significant amount of time as part of the process of modeling and simulation. For these reasons, the steps of data preparation as well as model verification and validation are investigated in more depth here.

Data is almost never directly suitable to be used “as is” with the simulation model. Because of this, data preparation, sometimes known as preprocessing, is necessary to extract and transform raw data into a form suitable for the model. Data preparation is, in essence, a model of the parameters for the simulation model. For RT models, two practicalities stand out. Firstly, any calculation that can be done prior to simulating decreases the computational load. Secondly, the data must be adapted regarding structure and type to suit the model, if only because RT models often approximate complicated physical relationships, as shown in Section 20.3.1, by using lookup tables.

Data preparation requires prior knowledge of the simulation model to know which data are required as both data and model are intimately linked. Designing the data preparation process can take up a substantial amount of time and end up being an iterative process. Data preparation can roughly be divided into (1) data extraction and (2) data transformation for our purposes here. The process is schematically depicted in [Figure 20.3](#_bookmark120).



Automotive Real-Time Simulation                               **509**

​                  

​            Raw data from      • Measurements      • Simulations      • Data sheets      • Spreadsheets            

​            Data extraction            

​            Data transformation            

​            • Parameter selection      • Unit conversion      • Removing outliers and invalid data            

​            Correct      and consistent data            

​            • Estimated data      • Data from existing models            

​            • Regression techniques        Input      data set      • Adapting data types        for simulation      • Formatting of data              model      structure                   (parameter      • Filtering/smoothing       lookup tables)      • Interpolation      • Extrapolation            







**FIGURE 20.3** Flow diagram of data preparation steps.

 

The sources of data are manifold. They could be measurements, simulation results, data sheets, or spread sheets provided from a supplier. For the case that not all input data is available, missing data must be estimated until the remaining data are provided. This may be sufficient to get the model up and running and to even start with testing. The following three steps will lead to correct and consistent data regarding units and values:

 

•   Parameter selection is the process of identifying the correct parameters necessary to parameterize the model. There may often be many more parameters measured or provided (e.g., in a data sheet) than is necessary.

•   Often the provided data is not specific in terms of physical units, coordinate systems, and measurement conditions. A typical problem that arises in engine applications is the absence of reference conditions for a table of turbocharger operating points, which renders the data practically unusable (Moraal and Kolmanovsky 1999). Some modeling languages such as Modelica or Simscape™ have variable classifications that support using correct units or even the type of variable such as force or mass.

•   Removing outliers and invalid data will be necessary as soon as measurements are intended to be used as model inputs or for the extraction of model parameters. Problems during experiments can be sensor failures or incorrect settings that can lead to invalid data.

 

Data transformation will process the data according to the model requirements regarding quality, type, and structure of the input data. Data quality refers to the smoothness of data and the availability of data as a usable format. Filtering and smoothing remove discontinuities in the input data. This can help prevent the simulation of models based on such data from aborting and increases computational efficiency even for cases where a simulation could run but must take small time steps over a discontinuity to satisfy tolerances. Because data were measured at scattered points, it is often necessary to carry out interpolation to map the values onto an equidistant grid. Extrapolation will extend input data to cover regions that lie beyond the range of the measurements. Regression techniques (Izenman 2008; Ljung 1999) are used to identify model input parameters from measured data. The type of parameter depends on the number of input variables and can be, for example, scalars or *n*-dimensional lookup tables. Finally, all input data must conform to the



**510**                             Real-Time Simulation Technologies

 

requirements of the simulation model with respect to file format, memory specifications, and similar formal matters. It is a part of the data transformation process to ensure such requirements are fulfilled.

An automated process can be very valuable for data preparation because, if implemented, the user is rewarded with a reliable, time-saving, and convenient method of creating the input data set necessary for the simulation model. This is especially advantageous when the input data have been modified or improved. Directly after data preparation, it is helpful to visualize the results. Simply visualizing data in the form of plots is not only a way of identifying errors in the data, it is also a way of understanding the simulation model and its implementation. One beneficial side effect of preparing data is revealed when the user of the simulation model also carries out the data preparation but was not involved in the modeling: The user is then forced to view the data that indicate how the model was implemented. In this manner, the user becomes more aware of the model while working with the data.

 

**20.3.3**              **M****odel** **V****eRifiCation and** **V****alidation**

Along with building a simulation model and preparing data to be used in the model, the process of verifying and validating (V&V) the simulation model is an essential step in striving toward accurate and reliable simulation results. Performing V&V is important for all types of simulation models but even more so for RT simulation applications where coupling to real-world subsystems requires quantitative correctness of the model behavior.

Model verification can be defined as ensuring that the computer program of the computerized model and its implementation are correct (Sargent 2007). This could be the transformation of a flowchart or a mathematical model consisting of equations into a computer program that can be executed. Model validation may be defined as substantiation that a computerized model within its domain of applicability possesses a satisfactory range of accuracy consistent with the intended application of the model (Schlesinger et al. 1979). The relationships between the computerized model, the conceptual model, and the technical system that is being modeled (the “real system”) are illustrated as the Sargent Circle shown in [Figure 20.4](#_bookmark121). The cross-dependencies stand out in the sense that the entire process of V&V is iterative. Finding a mistake late in the model validation phase may even require reevaluating the conceptual model and modifying it. Such a change can have an extensive influence on the model behavior, leading to an entirely new testing process that must be started from the very beginning. This can have far-reaching consequences as there may be other models or components being designed that depend on having an accurate model and the design of which now must be postponed. It is for this reason that modeling errors should be caught as soon as possible.

There are many principles that should be accounted for to ensure successful V&V. Some of the most prominent ones are

 

•   The simulation model is only valid for the tested conditions.

•   A valid model does not imply credible and accurate results.

•   Successful subsystem testing does not guarantee model credibility in its entirety.



Automotive Real-Time Simulation                               **511**

​                  

​            Real system             Operational validation      Experimentation            

​            Conceptual validation            

​            Analysis            

​            Computerized        Computer        Conceptual model          programming         model             Model verification            







**FIGURE 20.4** Simplistic overview of the process of model verification and validation. (From Sargent, R. G., *Proceedings of the 2007 Winter Simulation Conference*, Washington, DC, 2007. With permission.)

 

Carrying out V&V requires extensive testing for dynamic system models. One general method of doing this is presented by Lehmann (2003). Different types of tests are examined in Sargent (2007), for example:

 

•   Compare simulation results to real measured values from the technical system.

•   Compare simulation results to results from other valid models with at least comparable complexity.

•   Test extreme inputs or initial conditions.

•   Obtain expert opinion on the input–output relationship of model.

•   Perform steady-state and transient testing.

 

As suggested above, there can never be 100% validity. Ideally, the best chances for success derive from testing thoroughly and often by starting at the function level, continuing up through the subsystem and component level, and finally ending at the top system level. Each simulation model is unique, though, and so benefits from customized and detailed testing procedures. Moreover, testing thoroughly and efficiently is further complicated because the model implementation blends complex behavior on mathematical, numerical, and execution levels as described in the following section.

 

**20.3.4**              **f****RoM the** **M****odel to a** **Rt e****xeCutable**

Simulation in this context mainly denotes numerical time integration. Given the

​     

​        *x*,        



model of a dynamic system 0 = *f*(*x*, *. u*, *p*, *t*) with parameters *p*, control inputs *u*,



and the initial states *x*(*t* = *t*start), one can solve the initial-value problem by means of numerical integration schemes. As pointed out in Section 20.2, under RT condi-

tions one is mostly restricted to using schemes with a guaranteed execution time



**512**                             Real-Time Simulation Technologies

 

and, therefore, mainly to explicit and fixed-step-size methods. Unfortunately, these methods in particular provide limited accuracy and stability when solving stiff, discontinuous, or constrained systems that often arise in the field of engineering (EichSoellner and Führer 1998). In order to reconcile accuracy and efficiency, integration schemes can be carefully chosen for each domain and RT model or submodel. For example, higher order single-step methods, or approximations of implicit methods where iterative solutions are truncated (Eich-Soellner and Führer 1998), can be implemented in order to meet RT requirements. Some high-performance RT solutions are even able to switch the equations *and* integration schemes depending on the current engine model state (DYNA4Engine 2009).

Code generation is the final step influencing the performance of an executable RT simulator. Though tedious, some dynamics model descriptions, controller, and integration schemes are still implemented by manual coding, for example, for reasons of limited resources in embedded systems. However, nowadays this approach is restricted to specific automotive applications and very expensive because of the combinatorial complexity in terms of vehicle types and configurations. When using modeling formalisms such as Simulink, the high-level, possibly graphical, model description can be automatically transferred to C code or binaries for a specific RT platform or embedded system. Prevalent tools are Real-Time Workshop® or TargetLink for generating code from Simulink models. Dymola (2009) compiles textual or graphical models in Modelica. Exploiting a symbolic representation of the model offers interesting options to automatically enhance computational performance. Mixed-mode integration, and particularly the method of *inline-integration* (Elmqvist et al. 1995), leads to potentially large but computationally efficient code, especially attractive in RT applications.

[20.2 <--- ](20_2.md) [   Зміст   ](README.md) [--> 20.4](20_4.md)